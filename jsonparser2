import os
import glob
import yaml
import networkx as nx

from bokeh.plotting import figure, show
from bokeh.models import (ColumnDataSource, HoverTool, TapTool, CustomJS)
from bokeh.io import output_file

def find_yaml_files(directory):
    """
    Recursively searches for files with .yml or .yaml extensions
    in the specified directory and returns a list of absolute paths.
    """
    pattern_yml = os.path.join(directory, '**', '*.yml')
    pattern_yaml = os.path.join(directory, '**', '*.yaml')

    files = glob.glob(pattern_yml, recursive=True) + glob.glob(pattern_yaml, recursive=True)
    return [os.path.abspath(f) for f in files]

def parse_pipeline_file(yaml_file):
    """
    Parses a YAML file and returns a dictionary with keys:
      - 'dependencies': list of YAML file paths this file references
      - 'python_scripts': list of .py files mentioned in the file
      - 'schedules': list of any schedules found in this file

    This is a naive approach: 
      - We look for 'template' or 'extends' for YAML dependencies.
      - We do a broad check for any .py references.
      - We look at top-level 'schedules' (if it exists).
    """
    data = {
        'dependencies': [],
        'python_scripts': [],
        'schedules': []
    }

    base_dir = os.path.dirname(yaml_file)

    # Safely load the YAML
    try:
        with open(yaml_file, 'r', encoding='utf-8') as f:
            content = yaml.safe_load(f) or {}
    except Exception as e:
        print(f"Warning: Could not parse {yaml_file}. Error: {e}")
        return data

    # If not a dict, nothing to do
    if not isinstance(content, dict):
        return data

    # 1. Find YAML dependencies (template/extends)
    for key in {'template', 'extends'}:
        if key in content:
            value = content[key]
            if isinstance(value, str):
                if value.endswith(('.yml', '.yaml')):
                    dep_path = os.path.abspath(os.path.join(base_dir, value))
                    data['dependencies'].append(dep_path)
            elif isinstance(value, list):
                for v in value:
                    if isinstance(v, str) and v.endswith(('.yml', '.yaml')):
                        dep_path = os.path.abspath(os.path.join(base_dir, v))
                        data['dependencies'].append(dep_path)

    # 2. Find .py references (very naive approach)
    #    We'll do a recursive scan over the dictionary to find any string
    #    that ends with '.py'.
    def find_python_refs(item):
        if isinstance(item, str):
            if item.endswith('.py'):
                abs_py = os.path.abspath(os.path.join(base_dir, item))
                data['python_scripts'].append(abs_py)
        elif isinstance(item, dict):
            for v in item.values():
                find_python_refs(v)
        elif isinstance(item, list):
            for v in item:
                find_python_refs(v)

    find_python_refs(content)

    # 3. Find schedules (assuming top-level "schedules" key,
    #    typical in Azure Pipelines syntax)
    schedules = content.get('schedules')
    if schedules and isinstance(schedules, list):
        # Each schedule might have a cron, or displayName, etc.
        # We'll just store them as a string here.
        data['schedules'] = [str(sched) for sched in schedules]

    return data

def build_dependency_graph(yaml_files):
    """
    Builds a directed graph of YAML file dependencies.
    Each file is a node. 
    - Edges (A -> B) indicate A depends on B (for referencing other YAML files).
    - Also collects metadata (python scripts, schedules) for each node.
    """
    G = nx.DiGraph()

    # We will store file-based metadata in a dict for easy lookup
    file_metadata = {}

    # Parse each file for dependencies, scripts, schedules
    for yf in yaml_files:
        metadata = parse_pipeline_file(yf)
        file_metadata[yf] = metadata
        G.add_node(yf)  # add node if not already present

    # Add edges for dependencies
    for yf in yaml_files:
        deps = file_metadata[yf]['dependencies']
        for dep in deps:
            # Only add an edge if the dependency is actually in our set of YAML files
            if dep in yaml_files:
                G.add_edge(yf, dep)

    return G, file_metadata

def draw_graph_bokeh(G, file_metadata, output_html="yaml_dependencies.html"):
    """
    Draws the dependency graph using Bokeh for interactive visualization.
    Hovering shows file info; tapping a node shows an alert with metadata.
    """
    # Compute layout
    pos = nx.spring_layout(G, k=0.5, seed=42)

    nodes = list(G.nodes())
    edges = list(G.edges())

    # Map node -> index
    node_indices = {node: i for i, node in enumerate(nodes)}

    # Extract coords
    x_coords = [pos[n][0] for n in nodes]
    y_coords = [pos[n][1] for n in nodes]

    # Prepare edge coordinates
    edge_xs = []
    edge_ys = []
    for start, end in edges:
        edge_xs.append([pos[start][0], pos[end][0]])
        edge_ys.append([pos[start][1], pos[end][1]])

    # Build node metadata for Bokeh
    # Convert any lists to comma-separated strings for nicer display
    python_scripts_strs = []
    schedules_strs = []
    for n in nodes:
        md = file_metadata[n]
        py_str = ', '.join(md['python_scripts']) if md['python_scripts'] else "None"
        sch_str = ', '.join(md['schedules']) if md['schedules'] else "None"
        python_scripts_strs.append(py_str)
        schedules_strs.append(sch_str)

    # Create ColumnDataSources
    node_source = ColumnDataSource(data=dict(
        x=x_coords,
        y=y_coords,
        yaml_file=nodes,
        python_scripts=python_scripts_strs,
        schedules=schedules_strs
    ))

    edge_source = ColumnDataSource(data=dict(
        xs=edge_xs,
        ys=edge_ys
    ))

    # Create figure
    p = figure(
        title="Azure YAML Pipeline Dependencies (Interactive)",
        x_range=(-1.1, 1.1),
        y_range=(-1.1, 1.1),
        tools="pan,wheel_zoom,reset,save",
        active_scroll="wheel_zoom"
    )

    # Draw edges
    p.multi_line('xs', 'ys', source=edge_source, line_width=2, line_color="#888")

    # Draw nodes
    r_nodes = p.circle('x', 'y',
                       source=node_source,
                       size=15,
                       fill_color="lightblue",
                       line_color="black")

    # Hover tool
    hover_tool = HoverTool(
        renderers=[r_nodes],
        tooltips=[
            ("File", "@yaml_file"),
            ("Python Scripts", "@python_scripts"),
            ("Schedules", "@schedules")
        ]
    )
    p.add_tools(hover_tool)

    # Tap tool (click a node)
    tap_tool = TapTool(renderers=[r_nodes])
    p.add_tools(tap_tool)

    # JavaScript callback to show an alert with more info
    callback = CustomJS(args=dict(source=node_source), code="""
        const indices = source.selected.indices;
        if (indices.length > 0) {
            const i = indices[0];
            const filePath = source.data['yaml_file'][i];
            const pyScripts = source.data['python_scripts'][i];
            const schedules = source.data['schedules'][i];
            alert(
                "FILE: " + filePath 
                + "\\nPYTHON SCRIPTS: " + pyScripts
                + "\\nSCHEDULES: " + schedules
            );
        }
    """)
    p.js_on_event('tap', callback)

    # Write to HTML and display
    output_file(output_html)
    show(p)

def main(directory):
    """
    Main function to orchestrate finding YAML files, building the graph,
    and displaying the visualization using Bokeh, with extended metadata:
      - .py references
      - schedules
    """
    yaml_files = find_yaml_files(directory)
    print(f"Found {len(yaml_files)} YAML files.")
    G, file_metadata = build_dependency_graph(yaml_files)
    draw_graph_bokeh(G, file_metadata, output_html="yaml_dependencies.html")

if __name__ == "__main__":
    import sys
    if len(sys.argv) < 2:
        print(f"Usage: {sys.argv[0]} <directory>")
        sys.exit(1)

    directory_to_scan = sys.argv[1]
    main(directory_to_scan)
